#coding=utf-8

import re
import urllib2
from bs4 import BeautifulSoup

downloadLinks = 0
downloadMax = 500
downloaddir = './download/'

for num in range(2,1000):
    if downloadLinks >= downloadMax:
        break

    u = "http://download.cnet.com/windows/3150-20_4-0-" + str(num) + ".html?sort=reviewDate" # from download.com
    page = urllib2.urlopen(u)
    soup = BeautifulSoup(page)

    for link in soup.find_all("div", attrs={"data-dl-url": re.compile('.*\.exe$')}):
        if downloadLinks >= downloadMax:
            break

        url = link.get('data-dl-url')

        wordItems = url.split('/')
        for item in wordItems:                            #遍历每个字符串
            if re.match('.*\.exe$', item):                #查找exe的文件名
                if '?' in item:
                    filename = item.split('?')[0]
                else:
                    filename = item                       #查找到exe文件名
        localpath = downloaddir + filename                #将本地存储目录和需要提取的exe文件名进行连接

        try:
            fp = urllib2.urlopen(url, timeout=5)

            with open(localpath, "wb") as code:
                content = fp.read()
                length = len(content)
                if length > 1024 and length < 1024 * 1024 * 10:
                    code.write(content)
                    downloadLinks = downloadLinks + 1
        except:
            continue

print downloadLinks